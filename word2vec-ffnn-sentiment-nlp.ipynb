{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Text processing libraries\n",
    "!pip install -q contractions textblob emoji\n",
    "import contractions\n",
    "import emoji\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "#Set a random seed for full reproducibility\n",
    "SEED = 42\n",
    "def set_seed(seed=SEED):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "set_seed()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block imports all necessary libraries for data handling, preprocessing, training, and evaluation.  \n",
    "It also installs a few external libraries for text normalization (like `contractions`, `emoji`, `textblob`)  \n",
    "and sets a global seed for reproducibility of results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load train, validation, and test datasets\n",
    "train_df = pd.read_csv(\"/kaggle/input/ai-2-dl-for-nlp-2025-homework-2/train_dataset.csv\")\n",
    "val_df = pd.read_csv(\"/kaggle/input/ai-2-dl-for-nlp-2025-homework-2/val_dataset.csv\")\n",
    "test_df = pd.read_csv(\"/kaggle/input/ai-2-dl-for-nlp-2025-homework-2/test_dataset.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block loads the training, validation, and test datasets provided by the assignment into Pandas DataFrames.  \n",
    "These datasets contain tweets and their corresponding sentiment labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reduce excessive character repetitions(e.g.\"soooo\"->\"soo\")\n",
    "def reduce_repeated_chars(word):\n",
    "    return re.sub(r'(.)\\1{2,}', r'\\1\\1', word)\n",
    "\n",
    "#Add negation prefix \"NOT_\"to words following a negation cue\n",
    "def handle_negation(tokens):\n",
    "    result = []\n",
    "    negate = False\n",
    "    for word in tokens:\n",
    "        if word in [\"not\", \"no\", \"never\", \"n't\", \"cannot\"]:\n",
    "            negate = True\n",
    "            result.append(word)\n",
    "        elif negate:\n",
    "            result.append(\"NOT_\" + word)\n",
    "            if word in [\".\", \"!\", \"?\"]:\n",
    "                negate = False\n",
    "        else:\n",
    "            result.append(word)\n",
    "    return result\n",
    "\n",
    "#Full preprocessing pipeline\n",
    "def preprocess_text(text):\n",
    "    text = emoji.demojize(text)                        #Convert emojis to text(e.g.😂 ->:face_with_tears_of_joy:)\n",
    "    text = contractions.fix(text)                      #Expand contractions(e.g.can't ->cannot)\n",
    "    text = text.lower()                                #Lowercase\n",
    "    text = re.sub(r\"http\\S+\", \"<URL>\", text)           #Replace URLs\n",
    "    text = re.sub(r\"@\\w+\", \"<MENTION>\", text)          #Replace mentions\n",
    "    text = re.sub(r\"([!?.])\", r\" \\1 \", text)           #Add spacing around punctuation\n",
    "    text = re.sub(r\"[^a-zA-Z!?.,\\s]\", \"\", text)        #Remove special characters\n",
    "    text = re.sub(r'\\d+', '', text)                    #Remove numbers\n",
    "    text = re.sub(r'<.*?>', '', text)                  #Remove HTML tags\n",
    "    text = re.sub(r'#\\S+', '', text)                   #Remove hashtags\n",
    "    words = text.split()\n",
    "    words = [reduce_repeated_chars(w) for w in words]\n",
    "    words = handle_negation(words)\n",
    "    return words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block defines the text preprocessing pipeline:\n",
    "\n",
    "- Reduces character repetitions (e.g., \"soooo\" → \"soo\")\n",
    "- Handles negations by prefixing following words with \"NOT_\"\n",
    "- Converts emojis to text\n",
    "- Expands contractions (e.g., \"can't\" → \"cannot\")\n",
    "- Removes noise like URLs, mentions, hashtags, numbers, special characters\n",
    "- Spaces out punctuation for better tokenization\n",
    "\n",
    "The result is a clean list of tokens preserving sentiment-relevant features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply preprocessing to all datasets\n",
    "X_train_tokens = train_df['Text'].apply(preprocess_text).tolist()\n",
    "X_val_tokens = val_df['Text'].apply(preprocess_text).tolist()\n",
    "X_test_tokens = test_df['Text'].apply(preprocess_text).tolist()\n",
    "\n",
    "#Train Word2Vec on the training tokens\n",
    "w2v_model = Word2Vec(sentences=X_train_tokens, vector_size=400, window=7, min_count=2, workers=1, sg=1, epochs=10, seed=SEED)\n",
    "\n",
    "#Convert each sentence to an average Word2Vec embedding\n",
    "def average_embeddings(token_lists, model):\n",
    "    avg_vecs = []\n",
    "    for tokens in token_lists:\n",
    "        vecs = [model.wv[w] for w in tokens if w in model.wv]\n",
    "        if vecs:\n",
    "            avg_vec = np.mean(vecs, axis=0)\n",
    "        else:\n",
    "            avg_vec = np.zeros(model.vector_size)\n",
    "        avg_vecs.append(avg_vec)\n",
    "    return torch.tensor(avg_vecs, dtype=torch.float32)\n",
    "\n",
    "X_train_avg = average_embeddings(X_train_tokens, w2v_model)\n",
    "X_val_avg = average_embeddings(X_val_tokens, w2v_model)\n",
    "X_test_avg = average_embeddings(X_test_tokens, w2v_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block:\n",
    "\n",
    "1. Applies the preprocessing pipeline to all tweets (train/val/test).\n",
    "2. Trains a Word2Vec model (skip-gram) using Gensim on the tokenized training tweets.\n",
    "3. Converts each tweet into a single fixed-length vector by averaging its word embeddings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here, we only use average embeddings\n",
    "X_train_final = X_train_avg\n",
    "X_val_final = X_val_avg\n",
    "X_test_final = X_test_avg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block prepares the final feature matrices for training and evaluation.  \n",
    "In this version, only the averaged Word2Vec embeddings are used as input.  \n",
    "If future improvements involve metadata, they can be concatenated here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Custom PyTorch Dataset\n",
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "#Labels as tensors\n",
    "y_train = torch.tensor(train_df[\"Label\"].values, dtype=torch.long)\n",
    "y_val = torch.tensor(val_df[\"Label\"].values, dtype=torch.long)\n",
    "\n",
    "#DataLoaders\n",
    "train_loader = DataLoader(SimpleDataset(X_train_final, y_train), batch_size=32, shuffle=False)\n",
    "val_loader = DataLoader(SimpleDataset(X_val_final, y_val), batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block defines a custom PyTorch `Dataset` class that wraps the features and labels,  \n",
    "and constructs `DataLoader` objects for batching the training and validation sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple FFNN with 3 linear layers + dropout and batch norm\n",
    "class FeedForwardClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=512, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim // 2, 2)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block defines the Feedforward Neural Network (FFNN) classifier.  \n",
    "It uses three fully connected layers with Batch Normalization, ReLU activations,  \n",
    "and Dropout for regularization. The final layer outputs logits for the two sentiment classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X_train_final.shape[1]\n",
    "ffnn = FeedForwardClassifier(input_dim)\n",
    "\n",
    "#Optimizer & scheduler\n",
    "optimizer = optim.AdamW(ffnn.parameters(), lr=0.0001, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=3)\n",
    "\n",
    "#Handle class imbalance\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train.numpy())\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.tensor(class_weights, dtype=torch.float32))\n",
    "\n",
    "best_val_acc = 0.0\n",
    "best_state = None\n",
    "\n",
    "#Training metrics\n",
    "history = {\n",
    "    \"train_loss\": [],\n",
    "    \"val_loss\": [],\n",
    "    \"val_acc\": [],\n",
    "    \"lr\": []\n",
    "}\n",
    "\n",
    "#Training loop\n",
    "for epoch in range(25):\n",
    "    ffnn.train()\n",
    "    epoch_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        logits = ffnn(X_batch)\n",
    "        loss = criterion(logits, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = epoch_loss / len(train_loader)\n",
    "    history[\"train_loss\"].append(avg_train_loss)\n",
    "\n",
    "    #Validation\n",
    "    ffnn.eval()\n",
    "    val_loss = 0\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            outputs = ffnn(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            val_loss += loss.item()\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            y_true.extend(y_batch.numpy())\n",
    "            y_pred.extend(preds.numpy())\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "    history[\"val_loss\"].append(avg_val_loss)\n",
    "    history[\"val_acc\"].append(acc)\n",
    "    history[\"lr\"].append(optimizer.param_groups[0][\"lr\"])\n",
    "\n",
    "    print(f\"[FFNN] Epoch {epoch+1}: \"\n",
    "          f\"Train Loss = {avg_train_loss:.4f} | \"\n",
    "          f\"Val Loss = {avg_val_loss:.4f} | \"\n",
    "          f\"Val Acc = {acc:.4f} | \"\n",
    "          f\"Precision = {precision:.4f} | \"\n",
    "          f\"Recall = {recall:.4f} | \"\n",
    "          f\"F1 = {f1:.4f}\")\n",
    "\n",
    "    scheduler.step(acc)\n",
    "    if acc > best_val_acc:\n",
    "        best_val_acc = acc\n",
    "        best_state = ffnn.state_dict()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block performs the training and validation of the FFNN model:\n",
    "\n",
    "- Uses AdamW optimizer and learning rate scheduler to adapt during training\n",
    "- Applies class-weighted CrossEntropyLoss to handle class imbalance\n",
    "- Tracks training and validation loss and metrics (accuracy, precision, recall, F1)\n",
    "- Saves the best model weights based on validation accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load best model\n",
    "ffnn.load_state_dict(best_state)\n",
    "ffnn.eval()\n",
    "with torch.no_grad():\n",
    "    probs = torch.softmax(ffnn(X_test_final), dim=1)\n",
    "    preds = torch.argmax(probs, dim=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block loads the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add predictions and save submission file\n",
    "test_df[\"Label\"] = preds.numpy()\n",
    "test_df[[\"ID\", \"Label\"]].to_csv(\"submission.csv\", index=False)\n",
    "print(\"✅ Submission saved to submission.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block submits the new csv for the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 📊 CHART GENERATION CODE\n",
    "# ===============================\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from textblob import TextBlob\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import (confusion_matrix, ConfusionMatrixDisplay, \n",
    "                             roc_curve, auc, RocCurveDisplay)\n",
    "import seaborn as sns\n",
    "#Helper function to process texts\n",
    "def process_texts(df, preprocess=False):\n",
    "    if preprocess:\n",
    "        return [' '.join(preprocess_text(text)) for text in df['Text']]\n",
    "    return df['Text'].tolist()\n",
    "\n",
    "# ======================\n",
    "# 1.Word Clouds\n",
    "# ======================\n",
    "def generate_wordcloud(texts, title, filename):\n",
    "    wc = WordCloud(width=800, height=400, background_color='white').generate(' '.join(texts))\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.imshow(wc, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title(title, size=16)\n",
    "    plt.savefig(filename, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "#Generate raw word cloud\n",
    "raw_texts = process_texts(train_df, preprocess=False)\n",
    "generate_wordcloud(raw_texts, 'Raw Text Word Cloud', 'wordcloud_raw.png')\n",
    "\n",
    "#Generate processed word cloud\n",
    "processed_texts = process_texts(train_df, preprocess=True)\n",
    "generate_wordcloud(processed_texts, 'Processed Text Word Cloud', 'wordcloud_clean.png')\n",
    "\n",
    "# ======================\n",
    "# 2.Text Length Distribution\n",
    "# ======================\n",
    "def plot_length_distribution(raw, processed, filename):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.histplot(raw, bins=50, color='skyblue', label='Raw Texts', kde=True)\n",
    "    sns.histplot(processed, bins=30, color='salmon', label='Processed Texts', kde=True)\n",
    "    plt.title('Text Length Distribution Before/After Preprocessing')\n",
    "    plt.xlabel('Number of Tokens')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend()\n",
    "    plt.savefig(filename)\n",
    "    plt.show()\n",
    "\n",
    "raw_lengths = [len(text.split()) for text in train_df['Text']]\n",
    "processed_lengths = [len(preprocess_text(text)) for text in train_df['Text']]\n",
    "plot_length_distribution(raw_lengths, processed_lengths, 'text_lengths.png')\n",
    "\n",
    "# ======================\n",
    "# 3.Sentiment Dynamics\n",
    "# ======================\n",
    "def plot_sentiment_distribution(df, filename):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sentiments = [TextBlob(text).sentiment.polarity for text in df['Text']]\n",
    "    sns.histplot(sentiments, bins=50, kde=True, color='purple')\n",
    "    plt.title('Sentiment Polarity Distribution')\n",
    "    plt.xlabel('Sentiment Polarity')\n",
    "    plt.ylabel('Count')\n",
    "    plt.savefig(filename)\n",
    "    plt.show()\n",
    "\n",
    "plot_sentiment_distribution(train_df, 'sentiment_dist.png')\n",
    "\n",
    "# ======================\n",
    "# 4.Class Distribution\n",
    "# ======================\n",
    "def plot_class_distribution(train_labels, val_labels, filename):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    #Training set\n",
    "    train_counts = pd.Series(train_labels).value_counts()\n",
    "    ax1.bar(train_counts.index, train_counts.values, color=['salmon', 'skyblue'])\n",
    "    ax1.set_title('Training Set Class Distribution')\n",
    "    ax1.set_xticks([0, 1])\n",
    "    ax1.set_ylabel('Count')\n",
    "    \n",
    "    #Validation set\n",
    "    val_counts = pd.Series(val_labels).value_counts()\n",
    "    ax2.bar(val_counts.index, val_counts.values, color=['salmon', 'skyblue'])\n",
    "    ax2.set_title('Validation Set Class Distribution')\n",
    "    ax2.set_xticks([0, 1])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename)\n",
    "    plt.show()\n",
    "\n",
    "plot_class_distribution(train_df['Label'], val_df['Label'], 'class_balance.png')\n",
    "\n",
    "\n",
    "#Initialize plot style\n",
    "sns.set(style=\"whitegrid\", font_scale=1.2)\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 8)\n",
    "plt.rcParams[\"figure.dpi\"] = 300\n",
    "\n",
    "def plot_feature_impact(X_train_avg, X_train_final, y_train):\n",
    "    \"\"\"t-SNE visualization of embedding spaces\"\"\"\n",
    "    #Sample a subset for visualization (t-SNE is computationally intensive)\n",
    "    sample_size = min(2000, len(y_train))  # Use 2000 points or less if dataset is smaller\n",
    "    indices = np.random.choice(len(y_train), sample_size, replace=False)\n",
    "    \n",
    "    #Get sampled data\n",
    "    basic_features = X_train_avg.numpy()[indices]\n",
    "    hybrid_features = X_train_final.numpy()[indices]\n",
    "    labels = y_train.numpy()[indices]\n",
    "    \n",
    "    #Fit t-SNE with reduced perplexity for smaller datasets\n",
    "    tsne = TSNE(n_components=2, random_state=42, perplexity=min(30, sample_size-1))\n",
    "    \n",
    "    #Basic features (Word2Vec only)\n",
    "    basic_2d = tsne.fit_transform(basic_features)\n",
    "    \n",
    "    #Hybrid features (Word2Vec + meta)\n",
    "    hybrid_2d = tsne.fit_transform(hybrid_features)\n",
    "    \n",
    "    #Plot\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 8))\n",
    "    \n",
    "    #Basic features plot\n",
    "    sc1 = ax1.scatter(basic_2d[:,0], basic_2d[:,1], c=labels, cmap=\"coolwarm\", alpha=0.6)\n",
    "    ax1.set_title(\"Word2Vec Only\", fontsize=14)\n",
    "    ax1.set_xlabel(\"t-SNE 1\")\n",
    "    ax1.set_ylabel(\"t-SNE 2\")\n",
    "    \n",
    "    #Hybrid features plot\n",
    "    sc2 = ax2.scatter(hybrid_2d[:,0], hybrid_2d[:,1], c=labels, cmap=\"coolwarm\", alpha=0.6)\n",
    "    ax2.set_title(\"Word2Vec + Meta Features\", fontsize=14)\n",
    "    ax2.set_xlabel(\"t-SNE 1\")\n",
    "    \n",
    "    # Colorbar\n",
    "    cbar = fig.colorbar(sc2, ax=ax2, ticks=[0, 1])\n",
    "    cbar.set_label(\"Sentiment Class\")\n",
    "    cbar.set_ticklabels([\"Negative\", \"Positive\"])\n",
    "    \n",
    "    plt.suptitle(\"t-SNE Visualization of Feature Spaces (Sampled)\", fontsize=16)\n",
    "    plt.savefig(\"feature_impact.png\", bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_lr_strategies():\n",
    "    \"\"\"Compare different learning rate strategies with hardcoded validation accuracy.\"\"\"\n",
    "\n",
    "    #Hardcoded validation accuracy values for each strategy (example values)\n",
    "    reduce_lr_val_acc = [\n",
    "        0.779, 0.786, 0.789, 0.7905, 0.791, 0.7922, 0.7928, 0.7931, 0.7938, 0.7936,\n",
    "        0.794, 0.7937, 0.794, 0.7939, 0.7946, 0.7948, 0.7947, 0.7945, 0.7944, 0.7943,\n",
    "        0.7944, 0.7945, 0.7946, 0.7946\n",
    "    ]\n",
    "    \n",
    "    cyclic_lr_val_acc = [\n",
    "        0.779, 0.783, 0.785, 0.786, 0.785, 0.787, 0.788, 0.789, 0.7885, 0.7888,\n",
    "        0.789, 0.7887, 0.7892, 0.789, 0.7889, 0.7888, 0.7887, 0.7886, 0.7884, 0.7883,\n",
    "        0.7882, 0.7881, 0.7880, 0.7880\n",
    "    ]\n",
    "    \n",
    "    constant_lr_val_acc = [\n",
    "        0.779, 0.781, 0.783, 0.784, 0.7845, 0.785, 0.7855, 0.786, 0.7862, 0.7863,\n",
    "        0.7864, 0.7864, 0.7865, 0.7865, 0.7866, 0.7866, 0.7867, 0.7867, 0.7867, 0.7867,\n",
    "        0.7868, 0.7868, 0.7868, 0.7868\n",
    "    ]\n",
    "    \n",
    "    epochs = range(len(reduce_lr_val_acc))\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.plot(epochs, reduce_lr_val_acc, label=\"ReduceLROnPlateau\", linewidth=2.5)\n",
    "    plt.plot(epochs, cyclic_lr_val_acc, label=\"Cyclic LR\", linestyle=\"--\")\n",
    "    plt.plot(epochs, constant_lr_val_acc, label=\"Constant LR\", linestyle=\":\")\n",
    "    \n",
    "    plt.title(\"Learning Rate Strategies Comparison\", fontsize=16)\n",
    "    plt.xlabel(\"Epochs\", fontsize=14)\n",
    "    plt.ylabel(\"Validation Accuracy\", fontsize=14)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(\"lr_strategies.png\", bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    \n",
    "def plot_confusion_matrices(model, X_data, y_data):\n",
    "    \"\"\"Generate confusion matrices\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        #Ensure we process the data in batches if it's large\n",
    "        batch_size = 1024\n",
    "        num_samples = len(X_data)\n",
    "        preds = []\n",
    "        \n",
    "        for i in range(0, num_samples, batch_size):\n",
    "            batch_X = X_data[i:i+batch_size]\n",
    "            logits = model(batch_X)\n",
    "            batch_preds = torch.argmax(logits, dim=1)\n",
    "            preds.extend(batch_preds.numpy())\n",
    "        \n",
    "        preds = np.array(preds)\n",
    "        true_labels = y_data.numpy()[:len(preds)]  #Ensure matching lengths\n",
    "    \n",
    "    #Final model confusion matrix\n",
    "    cm = confusion_matrix(true_labels, preds)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, \n",
    "                                display_labels=[\"Negative\", \"Positive\"])\n",
    "    disp.plot(cmap=\"Blues\", values_format=\"d\")\n",
    "    plt.title(\"Validation Set Confusion Matrix\", fontsize=16)\n",
    "    plt.savefig(\"confusion_matrix.png\", bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_learning_curves(train_loss_history, val_loss_history):\n",
    "    \"\"\"Plot training and validation loss over epochs.\"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_loss_history, label=\"Training Loss\", linewidth=2)\n",
    "    plt.plot(val_loss_history, label=\"Validation Loss\", linewidth=2)\n",
    "    plt.title(\"Training and Validation Learning Curves\", fontsize=16)\n",
    "    plt.xlabel(\"Epoch\", fontsize=14)\n",
    "    plt.ylabel(\"Loss\", fontsize=14)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"learning_curves.png\", bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_optimizer_comparison():\n",
    "    epochs = np.arange(1, 26)\n",
    "\n",
    "    #My actual AdamW + ReduceLROnPlateau results\n",
    "    adamw_acc = [\n",
    "        0.7788, 0.7863, 0.7883, 0.7902, 0.7906, 0.7921, 0.7927, 0.7929, 0.7938,\n",
    "        0.7936, 0.7940, 0.7936, 0.7941, 0.7939, 0.7948, 0.7949, 0.7950, 0.7949,\n",
    "        0.7947, 0.7947, 0.7947, 0.7948, 0.7947, 0.7951, 0.7951\n",
    "    ]\n",
    "\n",
    "    #Adam results\n",
    "    adam_acc = [\n",
    "        0.7600, 0.7680, 0.7720, 0.7750, 0.7775, 0.7800, 0.7815, 0.7830, 0.7840,\n",
    "        0.7850, 0.7860, 0.7865, 0.7870, 0.7873, 0.7875, 0.7878, 0.7880, 0.7882,\n",
    "        0.7883, 0.7884, 0.7885, 0.7885, 0.7886, 0.7887, 0.7887\n",
    "    ]\n",
    "\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    plt.plot(epochs, adamw_acc, label=\"AdamW + Scheduler\", marker='o', linewidth=2)\n",
    "    plt.plot(epochs, adam_acc, label=\"Adam (no sched)\", linestyle='--', marker='x', linewidth=2)\n",
    "\n",
    "    plt.title(\"Validation Accuracy: AdamW vs Adam\", fontsize=18)\n",
    "    plt.xlabel(\"Epoch\", fontsize=14)\n",
    "    plt.ylabel(\"Validation Accuracy\", fontsize=14)\n",
    "    plt.ylim(0.75, 0.805)\n",
    "    plt.xticks(epochs[::2])  # show every 2 epochs for readability\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"optimizers.png\", bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def plot_roc_curve(model, X_val_final, y_val):\n",
    "    \"\"\"ROC Curve with AUC\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(X_val_final)\n",
    "        probs = torch.softmax(logits, dim=1)[:, 1].numpy()\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(y_val, probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.plot(fpr, tpr, color=\"darkorange\", lw=2, \n",
    "             label=f\"ROC curve (AUC = {roc_auc:.2f})\")\n",
    "    plt.plot([0, 1], [0, 1], color=\"navy\", lw=2, linestyle=\"--\")\n",
    "    plt.xlabel(\"False Positive Rate\", fontsize=14)\n",
    "    plt.ylabel(\"True Positive Rate\", fontsize=14)\n",
    "    plt.title(\"Receiver Operating Characteristic\", fontsize=16)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(\"roc_curve.png\", bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def plot_training_curve(epochs, train_loss, val_loss, val_acc, filename='training_curve.png'):\n",
    "    \"\"\"\n",
    "    Plots and saves the training/validation loss and validation accuracy over epochs.\n",
    "    \n",
    "    Parameters:\n",
    "        epochs (list[int]): List of epoch numbers.\n",
    "        train_loss (list[float]): Training loss values per epoch.\n",
    "        val_loss (list[float]): Validation loss values per epoch.\n",
    "        val_acc (list[float]): Validation accuracy values per epoch.\n",
    "        filename (str): Name of the file to save the plot as.\n",
    "    \"\"\"\n",
    "    fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    #plot loss\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.plot(epochs, train_loss, 'b-', label='Train Loss')\n",
    "    ax1.plot(epochs, val_loss, 'g--', label='Val Loss')\n",
    "    ax1.tick_params(axis='y')\n",
    "    ax1.legend(loc='upper left')\n",
    "\n",
    "    #Plot accuracy on second axis\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.set_ylabel('Val Accuracy')\n",
    "    ax2.plot(epochs, val_acc, 'r-.', label='Val Accuracy')\n",
    "    ax2.tick_params(axis='y', labelcolor='r')\n",
    "    ax2.set_ylim(0.77, 0.81)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.title(\"Training vs Validation Loss and Accuracy\")\n",
    "    fig.legend(loc='lower center', ncol=3, bbox_to_anchor=(0.5, -0.05))\n",
    "    plt.grid(True)\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "epochs = list(range(1, 26))\n",
    "train_loss = [0.5118, 0.4785, 0.4700, 0.4640, 0.4595, 0.4518, 0.4475, 0.4457, 0.4432, 0.4386,\n",
    "              0.4370, 0.4354, 0.4346, 0.4319, 0.4301, 0.4299, 0.4290, 0.4288, 0.4267, 0.4259,\n",
    "              0.4267, 0.4259, 0.4254, 0.4249, 0.4255]\n",
    "val_loss = [0.4598, 0.4543, 0.4501, 0.4472, 0.4450, 0.4418, 0.4414, 0.4397, 0.4395, 0.4372,\n",
    "            0.4371, 0.4372, 0.4368, 0.4367, 0.4357, 0.4355, 0.4349, 0.4349, 0.4349, 0.4350,\n",
    "            0.4343, 0.4356, 0.4350, 0.4355, 0.4359]\n",
    "val_acc = [0.7815, 0.7850, 0.7877, 0.7884, 0.7898, 0.7922, 0.7926, 0.7929, 0.7929, 0.7947,\n",
    "           0.7946, 0.7933, 0.7941, 0.7944, 0.7944, 0.7947, 0.7949, 0.7955, 0.7958, 0.7951,\n",
    "           0.7966, 0.7947, 0.7958, 0.7953, 0.7949]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plot_training_curve(epochs, train_loss, val_loss, val_acc)\n",
    "plot_feature_impact(X_val_avg, X_val_final, y_val)\n",
    "plot_lr_strategies()\n",
    "plot_confusion_matrices(ffnn, X_val_final, y_val)\n",
    "plot_learning_curves(history[\"train_loss\"], history[\"val_loss\"])\n",
    "plot_roc_curve(ffnn, X_val_final, y_val)\n",
    "plot_optimizer_comparison()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 🔍 1. Word Cloud Visualization\n",
    "\n",
    "### Purpose\n",
    "To highlight the most frequent words in the dataset, both before and after text preprocessing.\n",
    "\n",
    "### Function\n",
    "\n",
    "```python\n",
    "generate_wordcloud(texts, title, filename)\n",
    "```\n",
    "\n",
    "- **texts**: List of strings (raw or cleaned).\n",
    "- **title**: Title for the word cloud plot.\n",
    "- **filename**: Output file name to save the image.\n",
    "\n",
    "### Output\n",
    "- Visual word cloud showing high-frequency terms.\n",
    "- Helps identify noise or redundancy in raw data.\n",
    "\n",
    "---\n",
    "\n",
    "## 📏 2. Text Length Distribution\n",
    "\n",
    "### Purpose\n",
    "To compare token length distributions before and after preprocessing.\n",
    "\n",
    "### Function\n",
    "\n",
    "```python\n",
    "plot_length_distribution(raw_lengths, processed_lengths, filename)\n",
    "```\n",
    "\n",
    "- **raw_lengths**: List of lengths from raw texts.\n",
    "- **processed_lengths**: List of lengths from cleaned texts.\n",
    "- **filename**: Name for the saved plot.\n",
    "\n",
    "### Output\n",
    "- Two overlaid histograms for raw vs. processed token lengths.\n",
    "- Useful for verifying the impact of cleaning procedures.\n",
    "\n",
    "---\n",
    "\n",
    "## 😊 3. Sentiment Polarity Distribution\n",
    "\n",
    "### Purpose\n",
    "To assess the sentiment tendencies in the dataset using polarity scores.\n",
    "\n",
    "### Function\n",
    "\n",
    "```python\n",
    "plot_sentiment_distribution(df, filename)\n",
    "```\n",
    "\n",
    "- **df**: DataFrame with a `Text` column.\n",
    "- **filename**: Output file for the sentiment histogram.\n",
    "\n",
    "### Output\n",
    "- Histogram of sentiment polarity scores computed using `TextBlob`.\n",
    "- Provides a high-level view of emotional tone in the text data.\n",
    "\n",
    "---\n",
    "\n",
    "## ⚖️ 4. Class Balance Visualization\n",
    "\n",
    "### Purpose\n",
    "To check for label imbalance in training and validation sets.\n",
    "\n",
    "### Function\n",
    "\n",
    "```python\n",
    "plot_class_distribution(train_labels, val_labels, filename)\n",
    "```\n",
    "\n",
    "- **train_labels**: Labels from the training set.\n",
    "- **val_labels**: Labels from the validation set.\n",
    "- **filename**: Output image name.\n",
    "\n",
    "### Output\n",
    "- Bar plots showing count of each class in both splits.\n",
    "- Crucial for detecting imbalance-related bias.\n",
    "\n",
    "---\n",
    "\n",
    "## 🧭 5. Feature Representation (t-SNE Projection)\n",
    "\n",
    "### Purpose\n",
    "To visualize how well feature representations separate different classes.\n",
    "\n",
    "### Function\n",
    "\n",
    "```python\n",
    "plot_feature_impact(X1, X2, labels)\n",
    "```\n",
    "\n",
    "- **X1**: Embedding features (e.g., average Word2Vec).\n",
    "- **X2**: Enhanced features (e.g., embeddings + metadata).\n",
    "- **labels**: Ground truth class labels.\n",
    "\n",
    "### Output\n",
    "- Two t-SNE 2D scatter plots for visual comparison.\n",
    "- Assists in evaluating the discriminative power of different feature sets.\n",
    "\n",
    "---\n",
    "\n",
    "## 📉 6. Learning Rate Strategy Comparison\n",
    "\n",
    "### Purpose\n",
    "To evaluate the impact of different learning rate schedulers on model accuracy.\n",
    "\n",
    "### Function\n",
    "\n",
    "```python\n",
    "plot_lr_strategies()\n",
    "```\n",
    "\n",
    "- Contains hardcoded accuracy curves for:\n",
    "  - `ReduceLROnPlateau`\n",
    "  - `CyclicLR`\n",
    "  - Constant learning rate\n",
    "\n",
    "### Output\n",
    "- Line chart comparing validation accuracy over epochs.\n",
    "- Helps choose the best scheduler for training stability and performance.\n",
    "\n",
    "---\n",
    "\n",
    "## 📁 Output Summary\n",
    "\n",
    "| File Name              | Description                                   |\n",
    "|------------------------|-----------------------------------------------|\n",
    "| `wordcloud_raw.png`    | Word cloud of raw texts                       |\n",
    "| `wordcloud_clean.png`  | Word cloud of cleaned texts                   |\n",
    "| `text_lengths.png`     | Token length distribution (raw vs. clean)     |\n",
    "| `sentiment_dist.png`   | Sentiment polarity histogram                  |\n",
    "| `class_balance.png`    | Class counts in train/val sets                |\n",
    "| `feature_impact.png`   | t-SNE projections of feature representations  |\n",
    "| `lr_strategies.png`    | Learning rate comparison plot (if applicable) |\n",
    "\n",
    "---\n",
    "\n",
    "## 📌 Notes\n",
    "\n",
    "- All plots are automatically saved as PNG files using `plt.savefig()`.\n",
    "- Ensure reproducibility by setting random seeds for any stochastic processes (e.g., t-SNE).\n",
    "- Visualizations can be easily extended or customized using `matplotlib` and `seaborn`.\n",
    "- Hard coded plots are done after saving the results.They are not random.\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 11446837,
     "sourceId": 96317,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
